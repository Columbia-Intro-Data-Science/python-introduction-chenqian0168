{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import pylab as plt\n",
    "import seaborn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy.random as nprnd\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import lda\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Gathering and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prepocessing and Data integrity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>playerID</th>\n",
       "      <th>playNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37425</td>\n",
       "      <td>2137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>152038</td>\n",
       "      <td>1099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>112364</td>\n",
       "      <td>897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>38434</td>\n",
       "      <td>717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>117441</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  playerID  playNum\n",
       "0       0     37425     2137\n",
       "1       0    152038     1099\n",
       "2       0    112364      897\n",
       "3       0     38434      717\n",
       "4       0    117441      706"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "df = pd.read_csv(\"music.tsv\",delimiter='\\t',encoding='utf-8',header=None)\n",
    "# Rename the columns\n",
    "df.columns = ['userID','playerID','playerName','playNum']\n",
    "# Remove the missing values\n",
    "df.dropna(inplace=True)\n",
    "# Data cleaning and turned the complicated ID format to the simple one.\n",
    "_, user_id = np.unique(df.userID, return_inverse=True)\n",
    "_, player_id = np.unique(df.playerID, return_inverse=True)\n",
    "df['userID'] = user_id\n",
    "df['playerID'] = player_id\n",
    "df['userID'] = df['userID'].astype(np.int32)\n",
    "df['playerID'] = df['playerID'].astype(np.int32)\n",
    "df['playNum'] = df['playNum'].astype(np.int32)\n",
    "\n",
    "s_player = df[['playerID', 'playerName']].drop_duplicates(subset='playerID').set_index('playerID').sort_index()\n",
    "df.drop('playerName', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 17309316 entries, 0 to 17535654\n",
      "Data columns (total 3 columns):\n",
      "userID      int32\n",
      "playerID    int32\n",
      "playNum     int32\n",
      "dtypes: int32(3)\n",
      "memory usage: 330.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358857\n",
      "160110\n",
      "419157\n",
      "0\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(df.userID.max())\n",
    "print(df.playerID.max())\n",
    "print(df.playNum.max())\n",
    "print(df.userID.min())\n",
    "print(df.playerID.min())\n",
    "print(df.playNum.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot the matrix using sparse matrix. A low is a user, and each columns is the artist he listened, the values are the play times.\n",
    "user_item_sp_mat = coo_matrix((df.playNum, (df.userID, df.playerID)), (df.userID.max()+1, df.playerID.max()+1), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<358858x160111 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 17309316 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_sp_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection, Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is a unsupervised Problem. We used Latent Dirichlet allocation(LDA) to do the dimensions reduction which is clustering. We divided 160k artists into 20 class, according to the taste of users which is the latent variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Run LDA model\n",
    "lda = LatentDirichletAllocation(n_components=20, max_iter=10, random_state=0)\n",
    "lda.fit(user_item_sp_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.18521996e-02, 3.14321198e-01, 2.30725647e-01, ...,\n",
       "        2.98017515e-02, 1.22660813e-02, 2.99096728e-06],\n",
       "       [4.37706330e-02, 4.16937677e-07, 4.16937676e-07, ...,\n",
       "        4.16937677e-07, 1.88498698e-01, 7.73175606e-02],\n",
       "       [3.59918720e-01, 8.66400970e-06, 8.66400970e-06, ...,\n",
       "        8.66400979e-06, 4.32492087e-02, 5.84304083e-01],\n",
       "       ...,\n",
       "       [9.24385285e-06, 4.30781116e-02, 5.99731800e-02, ...,\n",
       "        1.04622041e-01, 4.14335390e-01, 3.14396062e-02],\n",
       "       [6.71952695e-06, 6.71952696e-06, 4.30781335e-01, ...,\n",
       "        1.66631953e-02, 6.71952695e-06, 6.71952695e-06],\n",
       "       [8.48303239e-03, 8.71115999e-03, 3.36927224e-05, ...,\n",
       "        3.36927225e-05, 1.91746895e-02, 3.36927231e-05]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.transform(user_item_sp_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the comparable number of points in each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160111\n",
      "160111\n",
      "160111\n",
      "160111\n",
      "160111\n",
      "160111\n",
      "160111\n",
      "160111\n",
      "160111\n",
      "160111\n",
      "160111\n",
      "160111\n",
      "160111\n",
      "160111\n",
      "160111\n",
      "160111\n",
      "160111\n",
      "160111\n",
      "160111\n",
      "160111\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,20):\n",
    "    print(lda.components_[[i]].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.985488059739923\n",
      "9.237519103879476\n",
      "13.94716914225564\n",
      "24.188243784157514\n",
      "77.32077605494896\n",
      "3.872186868157884\n",
      "13.20738904576523\n",
      "30.639151373011092\n",
      "6.211481279179348\n",
      "3.35539908088835\n",
      "19.632366139391845\n",
      "35.939598047667516\n",
      "50.592676166473446\n",
      "10.871454803867735\n",
      "27.260207464677848\n",
      "7.08892510033816\n",
      "2.0340641561144874\n",
      "46.088457479196805\n",
      "2.9897377197721373\n"
     ]
    }
   ],
   "source": [
    "# Check the covariance. In each cluster, inoder to check, we over it with 100000000\n",
    "for i in range(0,19):\n",
    "    print(np.cov(lda.components_[[i]])/100000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we can see that each cluster contains the same point number and in each cluster, the points are hight corrected with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretations for the clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \", \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: tom waits, sonic youth, animal collective, pixies, the magnetic fields\n",
      "Topic #1: nofx, bad religion, misfits, ramones, dropkick murphys\n",
      "Topic #2: nightwish, sonata arctica, blind guardian, kamelot, apocalyptica\n",
      "Topic #3: blink-182, fall out boy, my chemical romance, paramore, rise against\n",
      "Topic #4: the beatles, bob dylan, the rolling stones, johnny cash, u2\n",
      "Topic #5: miles davis, frank sinatra, johann sebastian bach, norah jones, amy winehouse\n",
      "Topic #6: opeth, in flames, slayer, katatonia, amon amarth\n",
      "Topic #7: pink floyd, metallica, iron maiden, ac/dc, queen\n",
      "Topic #8: tori amos, enya, hans zimmer, enigma, yann tiersen\n",
      "Topic #9: dir en grey, as i lay dying, bring me the horizon, larc~en~ciel, parkway drive\n",
      "Topic #10: red hot chili peppers, tool, queens of the stone age, foo fighters, incubus\n",
      "Topic #11: system of a down, linkin park, rammstein, in flames, koЯn\n",
      "Topic #12: radiohead, death cab for cutie, arctic monkeys, bloc party, sufjan stevens\n",
      "Topic #13: kanye west, lil wayne, eminem, 2pac, nas\n",
      "Topic #14: coldplay, britney spears, madonna, avril lavigne, the killers\n",
      "Topic #15: boards of canada, aphex twin, daft punk, the prodigy, burial\n",
      "Topic #16: kent, böhse onkelz, lars winnerbäck, håkan hellström, cmx\n",
      "Topic #17: radiohead, nine inch nails, muse, placebo, björk\n",
      "Topic #18: explosions in the sky, mogwai, god is an astronaut, 65daysofstatic, converge\n",
      "Topic #19: the cure, depeche mode, the smiths, morrissey, joy division\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_words(lda, s_player.playerName, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have 20 classes of artists now. We choose some classes to check the style of those artists. Topic 0 seems like Rock. Topic 1 is punk rock. We can conclude that if a user likes an artist in topic0, he also may like others artists in the same topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate properties of those clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lda.pkl']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(lda, 'lda.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 160111)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(358858, 20)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_components = lda.transform(user_item_sp_mat)\n",
    "user_components.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We reduced the dimensions of the original user-artist matrix into two matrixs. One is use 20 classes to represent users, according to the artists, the other one use 20 classes to represent artists, according to the users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The process to use the model. Input is a artist's name and output is the artist(s) in the same style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getName(name):\n",
    "    for i in range(s_player.shape[0]):\n",
    "        if s_player.iloc[i].playerName == name:\n",
    "            topic=lda.components_[:, i].argmax()\n",
    "            for j in range(0,9):\n",
    "                artists = lda.components_[[topic]].argsort(axis=1)\n",
    "                print(s_player.iloc[artists[0][-j]].playerName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "back 2 bass\n",
      "nofx\n",
      "bad religion\n",
      "misfits\n",
      "ramones\n",
      "dropkick murphys\n",
      "rancid\n",
      "against me!\n",
      "the clash\n"
     ]
    }
   ],
   "source": [
    "getName('bad religion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
